{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given input text in source language, identify terminology and dialogue styles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_text = \"\"\n",
    "with open(\"example2.txt\", \"r\") as file:\n",
    "    for line in file:\n",
    "        source_text += line.strip()\n",
    "        source_text += '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "GPT_MODEL = \"gpt-4\"\n",
    "def num_tokens(text: str, model: str = GPT_MODEL) -> int:\n",
    "    \"\"\"Return the number of tokens in a string.\"\"\"\n",
    "    encoding = tiktoken.encoding_for_model(model)\n",
    "    return len(encoding.encode(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_source_text(source_text: str, max_tokens: int = 8192) -> list[str]:\n",
    "    \"\"\"Chunk the source text into chunks with a maximum number of tokens.\"\"\"\n",
    "    chunks = []\n",
    "    chunk = \"\"\n",
    "    \n",
    "    for line in source_text.split('\\n'):\n",
    "        line_token_count = num_tokens(line)\n",
    "        \n",
    "        if line_token_count > max_tokens:\n",
    "            raise ValueError(f\"Line with more than {max_tokens} tokens\")\n",
    "        \n",
    "        chunk_token_count = num_tokens(chunk)\n",
    "\n",
    "        cut_here = (line.strip() == \"\" and chunk_token_count > max_tokens/8) \\\n",
    "            or (chunk_token_count + line_token_count > max_tokens)\n",
    "        \n",
    "        if cut_here:\n",
    "            chunks.append(chunk)\n",
    "            chunk = line + '\\n'\n",
    "        else:\n",
    "            chunk += line + '\\n'\n",
    "    \n",
    "    chunks.append(chunk)  # Append the last chunk\n",
    "    return chunks\n",
    "\n",
    "# chunks = chunk_source_text(source_text)\n",
    "# for chunk in chunks:\n",
    "#     print(f\"Chunk with {num_tokens(chunk)} tokens:\\n{chunk}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=os.environ.get(\"OPENAI_MANGA_API_KEY\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "genai.configure(api_key=os.getenv('GOOGLE_API_KEY'))\n",
    "gemini = genai.GenerativeModel('gemini-pro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions_1 = \"You are localizing an anime light novel. Identify named entities (such as proper nouns and unique terminologies) in the provided text passage and suggest English translations.\"\n",
    "instructions_2 = \"Do not redefine terms already in the glossary. \"\n",
    "instructions_3 = \"Output in JSON format: `{ \\\"original_word\\\": \\\"translated_word\\\", ... }`.\"\n",
    "\n",
    "def get_named_entities_from_gpt3(text: str, glossary: dict = None) -> str:\n",
    "    \"\"\"Ask GPT model to extract named entities from text.\"\"\"\n",
    "    glossary_instructions = instructions_2 if glossary else \"\"\n",
    "    instructions = instructions_1 + glossary_instructions + instructions_3\n",
    "    \n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": instructions},\n",
    "        {\"role\": \"user\", \"content\": text},\n",
    "    ]\n",
    "\n",
    "    if glossary:\n",
    "        sub_glossary = {k: v for k, v in glossary.items() if k in text}\n",
    "        sub_glossary_string = str(sub_glossary)\n",
    "        messages.insert(1, {\"role\": \"assistant\", \"content\": f\"Current glossary: {sub_glossary_string}\"})\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "    )\n",
    "\n",
    "    completion_message = completion.choices[0].message.content\n",
    "    return completion_message\n",
    "\n",
    "def get_named_entities_from_gpt4(text: str, glossary: dict = None) -> str:\n",
    "    \"\"\"Ask GPT model to extract named entities from text.\"\"\"\n",
    "    glossary_instructions = instructions_2 if glossary else \"\"\n",
    "    instructions = instructions_1 + glossary_instructions + instructions_3\n",
    "    \n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": instructions},\n",
    "        {\"role\": \"user\", \"content\": text},\n",
    "    ]\n",
    "\n",
    "    if glossary:\n",
    "        sub_glossary = {k: v for k, v in glossary.items() if k in text}\n",
    "        sub_glossary_string = str(sub_glossary)\n",
    "        messages.insert(1, {\"role\": \"assistant\", \"content\": f\"Current glossary: {sub_glossary_string}\"})\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4-turbo-preview\",\n",
    "        messages=messages,\n",
    "        response_format={ \"type\": \"json_object\" },\n",
    "        temperature=0,\n",
    "    )\n",
    "\n",
    "    completion_message = completion.choices[0].message.content\n",
    "    return completion_message\n",
    "\n",
    "def get_named_entities_from_gemini(text: str, glossary: dict = None) -> str:\n",
    "    glossary_instructions = instructions_2 if glossary else \"\"\n",
    "    instructions = instructions_1 + glossary_instructions + instructions_3\n",
    "\n",
    "    if glossary:\n",
    "        sub_glossary = {k: v for k, v in glossary.items() if k in text}\n",
    "        sub_glossary_string = str(sub_glossary)\n",
    "        instructions += f\" Current glossary: {sub_glossary_string}\"\n",
    "    \n",
    "    message = f\"{instructions}\\n\\nText:\\n```{text}```\"\n",
    "\n",
    "    response = gemini.generate_content(message)\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "def update_glossary(glossary: dict, new_terms: dict):\n",
    "    for k, v in new_terms.items():\n",
    "        if len(k) > 10: # too long\n",
    "            continue\n",
    "        glossary[k] = v\n",
    "\n",
    "def build_glossary_pipeline_gpt3(source_text: str) -> dict:\n",
    "    \"\"\"Extract named entities from source text and build terminology dictionary.\"\"\"\n",
    "    glossary = {}\n",
    "    chunks = chunk_source_text(source_text)\n",
    "\n",
    "    for chunk in chunks:\n",
    "        named_entities = get_named_entities_from_gpt3(chunk, glossary)\n",
    "        update_glossary(glossary, json.loads(named_entities))\n",
    "        print(str(glossary), end='\\r')\n",
    "\n",
    "    return glossary\n",
    "\n",
    "def build_glossary_pipeline_gemini(source_text: str) -> dict:\n",
    "    glossary = {}\n",
    "    chunks = chunk_source_text(source_text)\n",
    "\n",
    "    for text in chunks:\n",
    "        glossary_instructions = instructions_2 if glossary else \"\"\n",
    "        instructions = instructions_1 + glossary_instructions + instructions_3\n",
    "\n",
    "        if glossary:\n",
    "            sub_glossary = {k: v for k, v in glossary.items() if k in text}\n",
    "            sub_glossary_string = str(sub_glossary)\n",
    "            instructions += f\" Current glossary: {sub_glossary_string}\"\n",
    "        \n",
    "        message = f\"{instructions}\\n\\nText:\\n```{text}```\"\n",
    "        \n",
    "        chat = gemini.start_chat()\n",
    "        response = chat.send_message(\n",
    "            message,\n",
    "            generation_config=genai.types.GenerationConfig(\n",
    "                temperature=0\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        match = re.search(r\"{.*}\", response.text, re.DOTALL)\n",
    "        if match:\n",
    "            update_glossary(glossary, json.loads(match.group()))\n",
    "            print(str(glossary), end='\\r')\n",
    "\n",
    "    return glossary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"中考\": \"entrance exam\",\n",
      "  \"城原千太郎\": \"Shirohara Sentaro\",\n",
      "  \"雾乃雫\": \"Kirino Shizuku\",\n",
      "  \"樱\": \"Sakura\",\n",
      "  \"石田\": \"Ishida\",\n",
      "  \"BUNNYS\": \"Bunny's\",\n",
      "  \"神奈川县逗子海岸店\": \"Kanagawa Prefecture Zushi Coast Store\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "chunks = chunk_source_text(source_text)\n",
    "entities = get_named_entities_from_gemini(chunks[0])\n",
    "print(entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"城原千太郎\": \"Jōhara Chitarō\",\n",
      "  \"雾乃雫\": \"Kirino Shizuku\",\n",
      "  \"樱\": \"Sakura\",\n",
      "  \"石田\": \"Ishida\",\n",
      "  \"BUNNYS\": \"BUNNYS\",\n",
      "  \"神奈川县逗子海岸店\": \"Kanagawa Prefecture Zushi Coast Store\",\n",
      "  \"辻桥高中\": \"Tsujibashi High School\",\n",
      "  \"监督\": \"Director\",\n",
      "  \"棒球教练\": \"Baseball Coach\",\n",
      "  \"工程监理\": \"Construction Supervisor\",\n",
      "  \"旧视听室\": \"Old Audio-Visual Room\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "chunks = chunk_source_text(source_text, max_tokens=120000)\n",
    "entities = get_named_entities_from_gpt4(chunks[0])\n",
    "print(entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'城原千太郎': 'Chitara Johara', '雾乃雫': 'Kasumi Kirino', '电影导演': 'film director', '超级帅气角色': 'super handsome character', '樱': 'Sakura', '石田': 'Ishida', '中考': 'entrance exam', '学妹': 'junior student', '自行车': 'bicycle', '学长': 'senior student', '神奈川县逗子海岸店': 'Zushi Coast branch in Kanagawa Prefecture', '四月中旬': 'mid-April', '海风': 'sea breeze', '哈欠': 'yawn', '神奈川县立辻桥高中': 'Kanagawa Tsujiki High School', 'BUNNYS': 'BUNNYS', '芭菲': 'parfait', '喵喵收藏品': 'Meow Meow collectible', '辻桥高中': 'Tsujiki High School', 'A型血': 'blood type A', '归宅部': 'After-School Club', '家庭餐厅': 'family restaurant', '儿童午餐': \"children's lunch\", '监督': 'supervisor', '导演': 'director', '棒球教练': 'baseball coach', '工程监理': 'engineering supervisor', '英语笔记': 'English notes', '二年级': 'second year', '精通七国语言': 'fluent in seven languages', '不及格': 'failing grade', '黑暗': 'darkness', '玻璃杯': 'glass', '店长': 'store manager', '炒鱿鱼': 'get fired', '城原同学': 'Hirohara', '鹰野店长': 'Takanashi', '逗子海岸店': 'Zushi Coast Store', '逗子的人鱼': 'Zushi Mermaid', '逗子的鱼人': 'Zushi Fishman', '微观管理': 'micro-management', '经理培训': 'manager training', '给游戏氪金': 'spend money on in-game purchases', '春季抽卡': 'spring gacha', '冬眠': 'hibernation', '灯里': 'Tomari', '葛格': 'Gaku', '番茄酱': 'ketchup', '小鸟': 'little bird', '闲人免进': 'no entry for idle people', '训斥场所': 'reprimand place', '妹妹': 'younger sister', '手机': 'smartphone', '五岁': 'five years old', '演员': 'actor', '视听室': 'audiovisual room', '打工': 'part-time job', '社会规则': 'social rules', '约定': 'promise', '地狱': 'hell', '少女': 'girl'}\n"
     ]
    }
   ],
   "source": [
    "glossary = build_glossary_pipeline_gpt3(source_text)\n",
    "print(glossary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'城原千太郎': 'Chihara Sentaro', '雾乃雫': 'Kirino Shizuku', '樱': 'Sakura', '石田': 'Ishida', 'BUNNYS': 'BUNNYS', '神奈川县逗子海岸店': 'Kanagawa Prefecture Zushi Coast Store', '神奈川县立辻桥高中': 'Kanagawa Prefectural Tsujihashi High School', '辻桥高中': 'Tsujihashi High School', '辻桥高中二年B班': 'Tsujihashi High School, Class 2-B', '城原千太郎学长': 'Senior Chihara Sentaro', '监督': 'Supervisor', '城原同——学': 'Shirohara-kun', '鹰野': 'Takano', '逗子海岸': 'Zushi Kaigan', '逗子的人鱼': 'Mermaid of Zushi', '逗子的鱼人': 'Fishman of Zushi', '微观管理': 'Micromanagement', '葛格': 'Onii-chan', '灯里': 'Hotaru', '光之美少女角色扮演': 'PreCure cosplay', '危机(crisis)': 'crisis', '训斥场所': 'scolding place', '演员': 'Actor', '旧视听室': 'Old Audio-Visual Room', '学妹': 'Junior', '店长': 'Manager'}\n"
     ]
    }
   ],
   "source": [
    "glossary = build_glossary_pipeline_gemini(source_text)\n",
    "print(glossary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_1 = f\"You are localizing an anime light novel. Use the provided glossary with preferred terminology mappings to translate the following passage from Chinese to English. Match the style and tone of the original text. Output format: string of translated text only\"\n",
    "prompt_2 = \"Refine your translation to natural English without losing nuance. Output format: string of refined translation only\"\n",
    "\n",
    "def translate_chunk_with_gpt4(text: str, glossary: dict = None) -> str:\n",
    "    \"\"\"Translate a chunk of text using the GPT model.\"\"\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": prompt_1},\n",
    "        {\"role\": \"user\", \"content\": text},\n",
    "    ]\n",
    "\n",
    "    if glossary:\n",
    "        sub_glossary = {k: v for k, v in glossary.items() if k in text}\n",
    "        sub_glossary_string = str(sub_glossary)\n",
    "        messages.insert(1, {\"role\": \"assistant\", \"content\": f\"Glossary: {sub_glossary_string}\"})\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4-turbo-preview\",\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "    )\n",
    "\n",
    "    return completion.choices[0].message.content.strip()\n",
    "\n",
    "def refine_translation_with_gpt4(source_text: str, translated_text: str) -> str:\n",
    "    \"\"\"Refine a translation using the GPT model.\"\"\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are localizing an anime light novel.\"},\n",
    "        {\"role\": \"user\", \"content\": source_text},\n",
    "        {\"role\": \"assistant\", \"content\": translated_text},\n",
    "        {\"role\": \"user\", \"content\": prompt_2},\n",
    "    ]\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4-turbo-preview\",\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "    )\n",
    "\n",
    "    return completion.choices[0].message.content.strip()\n",
    "\n",
    "glossary = {'城原千太郎': 'Chitara Johara', '雾乃雫': 'Kasumi Kirino', '电影导演': 'film director', '超级帅气角色': 'super handsome character', '樱': 'Sakura', '石田': 'Ishida', '中考': 'entrance exam', '学妹': 'junior student', '自行车': 'bicycle', '学长': 'senior student', '神奈川县逗子海岸店': 'Zushi Coast branch in Kanagawa Prefecture', '四月中旬': 'mid-April', '海风': 'sea breeze', '哈欠': 'yawn', '神奈川县立辻桥高中': 'Kanagawa Tsujiki High School', 'BUNNYS': 'BUNNYS', '芭菲': 'parfait', '喵喵收藏品': 'Meow Meow collectible', '辻桥高中': 'Tsujiki High School', 'A型血': 'blood type A', '归宅部': 'After-School Club', '家庭餐厅': 'family restaurant', '儿童午餐': \"children's lunch\", '监督': 'supervisor', '导演': 'director', '棒球教练': 'baseball coach', '工程监理': 'engineering supervisor', '英语笔记': 'English notes', '二年级': 'second year', '精通七国语言': 'fluent in seven languages', '不及格': 'failing grade', '黑暗': 'darkness', '玻璃杯': 'glass', '店长': 'store manager', '炒鱿鱼': 'get fired', '城原同学': 'Hirohara', '鹰野店长': 'Takanashi', '逗子海岸店': 'Zushi Coast Store', '逗子的人鱼': 'Zushi Mermaid', '逗子的鱼人': 'Zushi Fishman', '微观管理': 'micro-management', '经理培训': 'manager training', '给游戏氪金': 'spend money on in-game purchases', '春季抽卡': 'spring gacha', '冬眠': 'hibernation', '灯里': 'Tomari', '葛格': 'Gaku', '番茄酱': 'ketchup', '小鸟': 'little bird', '闲人免进': 'no entry for idle people', '训斥场所': 'reprimand place', '妹妹': 'younger sister', '手机': 'smartphone', '五岁': 'five years old', '演员': 'actor', '视听室': 'audiovisual room', '打工': 'part-time job', '社会规则': 'social rules', '约定': 'promise', '地狱': 'hell', '少女': 'girl'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = chunk_source_text(source_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I, Chitara Johara, am a liar.\n",
      "I always hide my empty self deep within, wearing the masks of others to get through each day.\n",
      "However, one day, my high school life was disrupted by a cute little devil of a junior student, Kasumi Kirino.\n",
      "Kasumi, the \"film director,\" involved me in her independent film project with the rationale that \"lying is the beginning of an actor!\" \n",
      "And what she eagerly wanted to film was me playing a \"super handsome character\"!?\n",
      "\n",
      "Moreover, the popular girl in class—a straightforward girl and actress, Sakura, as well as the leader in sports, Ishida, also joined the team, and the filming began.\n",
      "But, due to a certain issue, the film production encountered difficulties.\n",
      "Behind it all was the hidden feelings of Kasumi—?\n",
      "\n",
      "Prologue\n",
      "\n",
      "You are my hero.\n",
      "Once, a middle school student said this to me, tears streaming down her face.\n",
      "\n",
      "—It was a Saturday morning when the streets began to be whitened by snow.\n",
      "The girl standing by the roadside seemed to be fighting against the winter chill.\n",
      "Snowflakes clung to her school uniform. Her hands, tightly holding the entrance exam admission slip, appeared exceptionally cold.\n",
      "From beneath the scarf that covered half of her face, her eyes seemed to be desperately holding back something.\n",
      "I knew at a glance that she must have encountered some trouble on this important day of the \"entrance exam.\"\n",
      "...It was none of my business, and I should have just passed by.\n",
      "I was supposed to quietly push my bicycle, shift my gaze to the plastic bag in the basket, and pretend not to see the girl as I walked past.\n",
      "But I couldn't even do such a simple thing, so I lied again.\n",
      "\n",
      "Future junior student, I'm here to help you.\n",
      "Are you lost? Did your smartphone die because of the cold? That's a disaster.\n",
      "It's okay, there's still time. So don't give up so easily, saying it's no use.\n",
      "I'll take you to the exam venue now. Hold on to me tightly, and never let go.\n",
      "\n",
      "The rusty bicycle moved forward with determination, and the girl on the back seat clung to my back, sobbing.\n",
      "The coat I bought yesterday must have been soaked with her tears. If such a person became my junior student, that would be something. Thinking this, I delivered her to the high school destination. She looked at me with eyes as if seeing a hero, her face covered with a scarf to hide the tear stains.\n",
      "She asked, are you a senior student at this school? I will never forget your great kindness.\n",
      "After bidding farewell to the figure with braided hair.\n",
      "I muttered to myself, kicking away the thin snow under my feet.\n",
      "\n",
      "\"...I'm not even a student at this school.\"\n",
      "\n",
      "Only two months had passed since that day.\n",
      "It was really cold that day.\n",
      "\n",
      "Scene 1\n",
      "\n",
      "Family restaurant BUNNYS, Zushi Coast branch in Kanagawa Prefecture.\n",
      "In mid-April, when the cherry blossom shadows gradually faded. The sweet aroma of the sea breeze came from outside.\n",
      "During the evening hours on a weekday, there were few customers, a relatively calm time. At such a moment.\n",
      "Me, Chitara Johara, responsible for greeting customers, yawned, and the girl in a school uniform sitting at a four-seater table shouted loudly.\n"
     ]
    }
   ],
   "source": [
    "translation = translate_chunk_with_gpt4(chunks[0], glossary)\n",
    "print(translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I, Chitara Johara, am a liar.\n",
      "I've always kept my hollow self hidden, donning others' masks to navigate each day.\n",
      "Yet, my mundane high school life was turned upside down by a charmingly devilish junior, Kasumi Kirino.\n",
      "Kasumi, the \"film director,\" roped me into her indie film project, proclaiming, \"Lying is the first step to becoming an actor!\" \n",
      "And to my astonishment, she was eager to cast me as a \"super cool character\"!?\n",
      "\n",
      "Additionally, the class's beloved actress with a straightforward personality, Sakura, and the athletic leader, Ishida, joined the crew, kickstarting the filming process.\n",
      "However, a certain issue threw a wrench in our production.\n",
      "At the heart of it all were Kasumi's concealed emotions—?\n",
      "\n",
      "Prologue\n",
      "\n",
      "\"You are my hero.\"\n",
      "A middle schooler once told me this, her face awash with tears.\n",
      "\n",
      "—It was a snowy Saturday morning, the streets slowly turning white.\n",
      "A girl stood by the roadside, seemingly battling the winter chill.\n",
      "Her school uniform was speckled with snowflakes, her hands clutching her exam admission slip, visibly cold.\n",
      "Her eyes, peeking out from under the scarf covering half her face, seemed to be holding back something desperately.\n",
      "At first glance, I could tell she was in trouble on this crucial day of the \"entrance exam.\"\n",
      "...It wasn't my concern, and I should have just walked by.\n",
      "I was supposed to quietly push my bike, divert my gaze to the plastic bag in the basket, and pretend I hadn't seen her.\n",
      "But I couldn't do even that simple act, so I lied again.\n",
      "\n",
      "\"Future junior, I'm here to help.\n",
      "Are you lost? Did your phone die from the cold? What a disaster.\n",
      "Don't worry, there's still time. So don't talk about giving up.\n",
      "I'll take you to the exam venue now. Hold on tight to me, and don't let go.\"\n",
      "\n",
      "The rusty bike moved steadfastly forward, with the girl on the back seat clinging to my back, sobbing.\n",
      "Her tears must have soaked the coat I had bought just yesterday. If such a person became my junior, that would be quite the story. With that thought, I delivered her to the high school. She looked at me with eyes that saw a hero, her face hidden by a scarf to cover the tear stains.\n",
      "She asked if I was a senior at this school, saying she would never forget my kindness.\n",
      "After watching her braided figure walk away,\n",
      "I muttered to myself, kicking away the thin layer of snow beneath my feet.\n",
      "\n",
      "\"...I'm not even a student at this school.\"\n",
      "\n",
      "Only two months had passed since that day.\n",
      "It was indeed very cold.\n",
      "\n",
      "Scene 1\n",
      "\n",
      "At the BUNNYS family restaurant, Zushi Coast branch in Kanagawa Prefecture.\n",
      "In mid-April, as the cherry blossom shadows began to fade, the sweet scent of the sea breeze wafted in.\n",
      "It was a quiet time during the weekday evening hours, with few customers around. At such a time,\n",
      "I, Chitara Johara, tasked with welcoming guests, let out a yawn, when the girl in a school uniform seated at a four-person table called out loudly.\n"
     ]
    }
   ],
   "source": [
    "refined_translation = refine_translation_with_gpt4(chunks[0], translation)\n",
    "print(refined_translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "manga-kernel",
   "language": "python",
   "name": "manga-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
